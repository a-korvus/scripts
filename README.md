# Скрипты

- ### crowler
  #### Реализация асинхронного интернет-краулера

  **Принцип работы**: на вход краулеру даётся список ссылок. Далее он запрашивает контент этих страниц, парсит их, достаёт все доступные ссылки и идёт по ним. Иначе говоря, он работает рекурсивно.<br>
  Количество итераций можно сконфигурировать (по умолчанию 3).<br>
  Все ссылки, которые краулер найдёт по ходу работы, записываются в файл.

- ### sql_conn
  #### Подключение к базе данных PostgreSQL, создание таблиц, наполнение данными
  Все связанные файлы лежат в директории `sql_conn`. В поддиректории `sql` - запросы для БД Postgres. Сама база данных поднимается в докере. Файл `main.py` содержит функции подключение к БД и выполнения запросов из папки `sql`.
